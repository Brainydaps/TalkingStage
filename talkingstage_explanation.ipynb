{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/adedapoadeniran/talkingstage-explanation?scriptVersionId=186159173\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# TalkingStageBot: Training and Usage Explanation\n\nThis notebook provides an overview of the `TalkingStageBot`, detailing how to train the model using the training data and how to use the trained model to generate responses to user questions. The bot utilizes machine learning techniques to classify and respond to user inputs.\n\n## 1. Setup and Dependencies\n\nWe start by importing the necessary libraries and setting up the environment.\n","metadata":{}},{"cell_type":"code","source":"# Import necessary libraries\nimport os\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\n\nfrom microsoft.ml import MLContext, DataViewSchema\nfrom microsoft.ml.data import TextLoaderSaverCatalog\nfrom microsoft.ml.transforms.text import FeaturizeText\nfrom microsoft.ml.trainers import SdcaMaximumEntropy\nfrom microsoft.ml.transforms import Concatenate\nfrom microsoft.ml.transformers import MapValueToKey, MapKeyToValue\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Loading and Preprocessing Data\n\nIn this section, we will load and preprocess the training data. The training data is assumed to be in a CSV file named `training_data.csv`.\n","metadata":{}},{"cell_type":"code","source":"# Load the training data\ntraining_data_path = 'path/to/training_data.csv'  # Update this path to the actual location of your training data\n\n# Define the InputData class for schema\nclass InputData:\n    def __init__(self, text, label):\n        self.Text = text\n        self.Label = label\n\n# Create an ML context\nml_context = MLContext()\n\n# Load the training data\ntraining_data = ml_context.Data.LoadFromTextFile(\n    path=training_data_path,\n    separatorChar=',',\n    hasHeader=True\n)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Data Preprocessing\n\nWe will preprocess the training data to ensure consistency. This includes converting text to lowercase and trimming whitespace.\n","metadata":{}},{"cell_type":"code","source":"# Preprocess the training data\npreprocessed_training_data = ml_context.Data.CreateEnumerable(\n    training_data,\n    reuseRowObject=False\n).select(lambda row: InputData(text=row.Text.strip().lower(), label=row.Label.strip().lower()))\n\n# Create an IDataView from preprocessed data\npreprocessed_training_data_view = ml_context.Data.LoadFromEnumerable(preprocessed_training_data)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Defining the Training Pipeline\n\nWe will define the data preparation and training pipeline. The pipeline includes text featurization, label mapping, and a classification trainer.\n","metadata":{}},{"cell_type":"code","source":"# Define the data preparation and training pipeline\npipeline = ml_context.Transforms.Text.FeaturizeText(\n    outputColumnName='Features',\n    inputColumnName='Text'\n).Append(\n    ml_context.Transforms.Conversion.MapValueToKey(\n        outputColumnName='LabelKey',\n        inputColumnName='Label'\n    )\n).Append(\n    ml_context.Transforms.Concatenate(\n        outputColumnName='Features',\n        inputColumnNames=['Features']\n    )\n).AppendCacheCheckpoint(ml_context).Append(\n    ml_context.MulticlassClassification.Trainers.SdcaMaximumEntropy(\n        labelColumnName='LabelKey',\n        featureColumnName='Features',\n        l2Regularization=0.1,\n        l1Regularization=0.01,\n        maximumNumberOfIterations=1000\n    )\n).Append(\n    ml_context.Transforms.Conversion.MapKeyToValue(\n        outputColumnName='PredictedLabel',\n        inputColumnName='PredictedLabel'\n    )\n)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Training the Model\n\nWe will train the model using the defined pipeline and save the trained model to a file named `model.zip`.\n","metadata":{}},{"cell_type":"code","source":"# Train the model\nmodel = pipeline.Fit(preprocessed_training_data_view)\n\n# Save the trained model\nmodel_path = 'path/to/model.zip'  # Update this path to the desired location to save the model\nml_context.Model.Save(model, preprocessed_training_data_view.Schema, model_path)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6. Using the Trained Model\n\nWe will demonstrate how to use the trained model to generate responses to user inputs.\n","metadata":{}},{"cell_type":"code","source":"# Load the trained model\nmodel = ml_context.Model.Load(model_path, out model_schema)\n\n# Define the function to predict responses\ndef get_response(question):\n    # Split input into individual questions\n    question_list = question.split(['.', '?', ',', '!'], remove_empty_entries=True)\n    responses_set = set()\n\n    for question in question_list:\n        lower_question = question.lower().strip()\n        # If no direct keyword match, use ML model prediction\n        prediction = predict(lower_question)\n        if prediction and prediction.PredictedLabel:\n            responses_set.add(prediction.PredictedLabel)\n        else:\n            responses_set.add(\"I don't have an answer for that.\")\n    \n    return ', '.join(responses_set)\n\n# Define the prediction function\ndef predict(text):\n    input_data = [{'Text': text}]\n    input_data_view = ml_context.Data.LoadFromEnumerable(input_data)\n    transformed_data = model.Transform(input_data_view)\n    predictions = ml_context.Data.CreateEnumerable(transformed_data, reuse_row_object=False).tolist()\n    return predictions[0] if predictions else None\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7. Testing the Bot\n\nLet's test the bot with a sample input.\n","metadata":{}},{"cell_type":"code","source":"# Test the bot with a sample input\nsample_input = \"What's your name? Where do you live?\"\nresponse = get_response(sample_input)\nprint(f\"Response: {response}\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Conclusion\n\nThis notebook provided an overview of the `TalkingStageBot`, from training the model to generating responses. You can further customize and improve the bot by updating the training data and fine-tuning the model parameters.\n","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}